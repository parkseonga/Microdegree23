{"cells":[{"cell_type":"markdown","metadata":{"id":"EhYzt-CxNiAz"},"source":["#### DataLoader"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2427,"status":"ok","timestamp":1702877080689,"user":{"displayName":"혜나","userId":"18133580631168845155"},"user_tz":-540},"id":"Inhgi0dWNkz2","outputId":"dbda666d-bcfa-4402-d580-2ee26e99c0b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1702877082213,"user":{"displayName":"혜나","userId":"18133580631168845155"},"user_tz":-540},"id":"TASed7rMOT9g","outputId":"a01b3124-a4c6-4394-f6e8-057e2a97bc77"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":331,"status":"ok","timestamp":1702877089848,"user":{"displayName":"혜나","userId":"18133580631168845155"},"user_tz":-540},"id":"MxNQL_h9OY9j","outputId":"b767232f-8732-464f-f093-9b6c672c9352"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/[Microdegree] Hypotension/code\n","/content/drive/MyDrive/Colab Notebooks/[Microdegree] Hypotension/code\n"]}],"source":["%cd /content/drive/MyDrive/Colab Notebooks/[Microdegree] Hypotension/code # change directory\n","!pwd"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1702872067183,"user":{"displayName":"혜나","userId":"18133580631168845155"},"user_tz":-540},"id":"OdYaDoKiNiA4"},"outputs":[],"source":["# !pip install torchsummary\n","# !pip install tensorboard\n","# !pip install wandb"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8092,"status":"ok","timestamp":1702877101291,"user":{"displayName":"혜나","userId":"18133580631168845155"},"user_tz":-540},"id":"C1qwNaX3NiA6"},"outputs":[],"source":["import numpy as np\n","from collections import Counter\n","from tqdm import tqdm\n","from matplotlib import pyplot as plt\n","\n","import os\n","import glob\n","import re\n","import pickle\n","import multiprocessing\n","import wandb\n","import argparse\n","from datetime import datetime\n","from pathlib import Path\n","import random\n","import json\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from torchsummary import summary\n","\n","from model_resnet1d import ResNet1D\n","from pytorchtools import EarlyStopping\n","\n","# from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, f1_score # classification\n","from sklearn.metrics import mean_absolute_percentage_error, r2_score # regression"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":483,"status":"ok","timestamp":1702877145866,"user":{"displayName":"혜나","userId":"18133580631168845155"},"user_tz":-540},"id":"tw4DIOzDNiA7","outputId":"ab3b9096-20c0-4482-aa9f-8f632894a2fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Namespace(seed=42, epochs=100, batch_size=128, lr=0.001, criterion='cross_entropy', log_interval=150, model='resnet1d', name='exp', model_dir='./model')\n"]}],"source":["def seed_everything(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","def increment_path(path, exist_ok=False):\n","    \"\"\" Automatically increment path, i.e. runs/exp --> runs/exp0, runs/exp1 etc.\n","\n","    Args:\n","        path (str or pathlib.Path): f\"{model_dir}/{args.name}\".\n","        exist_ok (bool): whether increment path (increment if False).\n","    \"\"\"\n","    path = Path(path)\n","    if (path.exists() and exist_ok) or (not path.exists()):\n","        return str(path)\n","    else:\n","        dirs = glob.glob(f\"{path}*\")\n","        matches = [re.search(rf\"%s(\\d+)\" % path.stem, d) for d in dirs]\n","        i = [int(m.groups()[0]) for m in matches if m]\n","        n = max(i) + 1 if i else 2\n","        return f\"{path}{n}\"\n","\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","\n","\n","_criterion_entrypoints = {\n","    'binary_cross_entropy': nn.BCEWithLogitsLoss, # nn.BCELoss,\n","    'cross_entropy': nn.CrossEntropyLoss,\n","}\n","\n","def criterion_entrypoint(criterion_name):\n","    return _criterion_entrypoints[criterion_name]\n","\n","def is_criterion(criterion_name):\n","    return criterion_name in _criterion_entrypoints\n","\n","def create_criterion(criterion_name, **kwargs):\n","    if is_criterion(criterion_name):\n","        create_fn = criterion_entrypoint(criterion_name)\n","        criterion = create_fn(**kwargs)\n","    else:\n","        raise RuntimeError('Unknown loss (%s)' % criterion_name)\n","    return criterion\n","\n","now = datetime.now()\n","folder_name = now.strftime('%Y-%m-%d-%H:%M:%S')\n","parser = argparse.ArgumentParser()\n","\n","parser.add_argument('--seed', type=int, default=42, help='random seed (default: 42)')\n","parser.add_argument('--epochs', type=int, default=100, help='number of epochs to train (default: 1)')\n","parser.add_argument('--batch_size', type=int, default=128, help='input batch size for training (default: 64)')\n","parser.add_argument('--lr', type=float, default=1e-3, help='learning rate (default: 1e-3)')\n","# parser.add_argument('--lr_decay_step', type=int, default=20, help='learning rate scheduler deacy step (default: 20)')\n","parser.add_argument('--criterion', type=str, default='cross_entropy', help='criterion type (default: cross_entropy)')\n","parser.add_argument('--log_interval', type=int, default=150, help='how many batches to wait before logging training status')\n","parser.add_argument('--model', type=str, default='resnet1d', help='model type (default: BaseModel)')\n","parser.add_argument('--name', default='exp', help='model save at {SM_MODEL_DIR}/{name}')\n","# parser.add_argument('--name', default='exp_'+folder_name, help='model save at {SM_MODEL_DIR}/{name}')\n","parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_MODEL_DIR', './model_clf'))\n","\n","# args = parser.parse_args()\n","args, _ = parser.parse_known_args()\n","print(args)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1702877164573,"user":{"displayName":"혜나","userId":"18133580631168845155"},"user_tz":-540},"id":"oudZ8_lONiA9","outputId":"bc5deac5-35d6-45fb-83d1-e29eb50f5258"},"outputs":[{"name":"stdout","output_type":"stream","text":["./model\n","model/cross_entropy_epoch100_batch128_exp\n"]}],"source":["model_dir = args.model_dir\n","# save_dir = increment_path(os.path.join(model_dir, args.name))\n","# save_dir = increment_path(os.path.join(model_dir, args.name+\"_\"+args.criterion+\"_\"+str(args.epochs)))\n","save_dir = increment_path(os.path.join(model_dir, args.criterion+\"_epoch\"+str(args.epochs)+\"_batch\"+str(args.batch_size)+\"_\"+args.name))\n","\n","print(model_dir)\n","print(save_dir)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":373,"status":"ok","timestamp":1702877166845,"user":{"displayName":"혜나","userId":"18133580631168845155"},"user_tz":-540},"id":"Kjo2ROfwNiA9"},"outputs":[],"source":["class PPGDataset(Dataset):\n","    def __init__(self, data, label):\n","        self.data = data\n","        self.label = label\n","\n","    def __getitem__(self, index):\n","        return (torch.as_tensor(self.data[index], dtype=torch.float), torch.as_tensor(self.label[index], dtype=torch.long)) # torch.long\n","\n","    def __len__(self):\n","        return len(self.data)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35581,"status":"ok","timestamp":1702877203463,"user":{"displayName":"혜나","userId":"18133580631168845155"},"user_tz":-540},"id":"uSKfSJChNiA_","outputId":"46ad8b99-0854-4381-d8b2-1cb6568a184c"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'torch.Tensor'> <class 'torch.Tensor'>\n","torch.Size([189429, 1, 3000]) torch.Size([189429, 1])\n","\n","<class 'torch.Tensor'> <class 'torch.Tensor'>\n","torch.Size([62746, 1, 3000]) torch.Size([62746, 1])\n","\n","<class 'torch.Tensor'> <class 'torch.Tensor'>\n","torch.Size([60287, 1, 3000]) torch.Size([60287, 1])\n","\n","<__main__.PPGDataset object at 0x7a3b56a12ad0>\n","<__main__.PPGDataset object at 0x7a3b56a12a70>\n","<__main__.PPGDataset object at 0x7a3b56a12b60>\n"]}],"source":["# get dataset\n","with open('../data_clf/train_clf_scaled_x.pkl', 'rb') as f:\n","    # train_X = pickle.load(f)\n","    X = pickle.load(f)\n","    train_X = np.expand_dims(X, 1)\n","    train_X = torch.tensor(train_X, dtype = torch.float32)\n","with open('../data_clf/train_clf_y.pkl', 'rb') as f:\n","    # train_Y = pickle.load(f)\n","    Y = pickle.load(f)\n","    train_Y = np.expand_dims(Y, 1)\n","    train_Y = torch.tensor(train_Y, dtype = torch.float32)\n","\n","with open('../data_clf/valid_clf_scaled_x.pkl', 'rb') as f:\n","    # valid_X = pickle.load(f)\n","    X = pickle.load(f)\n","    valid_X = np.expand_dims(X, 1)\n","    valid_X = torch.tensor(valid_X, dtype = torch.float32)\n","with open('../data_clf/valid_clf_y.pkl', 'rb') as f:\n","    # valid_Y = pickle.load(f)\n","    Y = pickle.load(f)\n","    valid_Y = np.expand_dims(Y, 1)\n","    valid_Y = torch.tensor(valid_Y, dtype = torch.float32)\n","\n","with open('../data_clf/test_clf_scaled_x.pkl', 'rb') as f:\n","    # test_X = pickle.load(f)\n","    X = pickle.load(f)\n","    test_X = np.expand_dims(X, 1)\n","    test_X = torch.tensor(test_X, dtype = torch.float32)\n","with open('../data_clf/test_clf_y.pkl', 'rb') as f:\n","    # test_Y = pickle.load(f)\n","    Y = pickle.load(f)\n","    test_Y = np.expand_dims(Y, 1)\n","    test_Y = torch.tensor(test_Y, dtype = torch.float32)\n","\n","train_dataset = PPGDataset(train_X, train_Y)\n","val_dataset = PPGDataset(valid_X, valid_Y)\n","test_dataset = PPGDataset(test_X, test_Y)\n","\n","print(type(train_X), type(train_Y))\n","print(train_X.shape, train_Y.shape)\n","# print(len(train_X), len(train_Y))\n","# print(len(train_X[0]), train_X[0])\n","# print(train_Y[:20])\n","print()\n","print(type(valid_X), type(valid_Y))\n","print(valid_X.shape, valid_Y.shape)\n","# print(len(valid_X), len(valid_Y))\n","# print(len(valid_X[0]), valid_X[0])\n","# print(valid_Y[:20])\n","print()\n","print(type(test_X), type(test_Y))\n","print(test_X.shape, test_Y.shape)\n","# print(len(test_X), len(test_Y))\n","# print(len(test_X[0]), test_X[0])\n","# print(test_Y[:20])\n","print()\n","\n","print(train_dataset)\n","print(val_dataset)\n","print(test_dataset)\n","\n","# <class 'torch.Tensor'> <class 'torch.Tensor'>\n","# torch.Size([189429, 1, 3000]) torch.Size([189429, 1])\n","\n","# <class 'torch.Tensor'> <class 'torch.Tensor'>\n","# torch.Size([62746, 1, 3000]) torch.Size([62746, 1])\n","\n","# <class 'torch.Tensor'> <class 'torch.Tensor'>\n","# torch.Size([62746, 1, 3000]) torch.Size([62746, 1])"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":446,"status":"ok","timestamp":1702877233908,"user":{"displayName":"혜나","userId":"18133580631168845155"},"user_tz":-540},"id":"W8_nv7PBNiBA","outputId":"20581ce0-0e6b-41dd-deb0-27651032f4ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n","<torch.utils.data.dataloader.DataLoader object at 0x7a3c6821fa30>\n","<torch.utils.data.dataloader.DataLoader object at 0x7a3b56a13cd0>\n","<torch.utils.data.dataloader.DataLoader object at 0x7a3b56a128c0>\n"]}],"source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=args.batch_size,\n","    num_workers=multiprocessing.cpu_count() // 2,\n","    shuffle=True,\n","    pin_memory=use_cuda,\n","    drop_last=True,\n","    )\n","\n","val_dataloader = DataLoader(\n","    val_dataset,\n","    batch_size=args.batch_size,\n","    num_workers=multiprocessing.cpu_count() // 2,\n","    shuffle=False,\n","    pin_memory=use_cuda,\n","    drop_last=True,\n","    )\n","\n","test_dataloader = DataLoader(\n","    test_dataset,\n","    batch_size=args.batch_size, # 1024, #\n","    num_workers=multiprocessing.cpu_count() // 2,\n","    shuffle=False,\n","    pin_memory=use_cuda,\n","    drop_last=False,\n",")\n","\n","print(device)\n","print(train_dataloader)\n","print(val_dataloader)\n","print(test_dataloader)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1488,"status":"ok","timestamp":1702877241719,"user":{"displayName":"혜나","userId":"18133580631168845155"},"user_tz":-540},"id":"rGfN2C0NNiBB","outputId":"70ead52b-25cf-4e5c-e7c8-389d202ddecd"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find notebook name here.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhyenagatha02\u001b[0m (\u001b[33msixseg\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"notebook name here\"\n","\n","# !pip install wandb -qqq\n","# import wandb\n","wandb.login()\n","# !wandb login --relogin"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"executionInfo":{"elapsed":1876,"status":"ok","timestamp":1702877247347,"user":{"displayName":"혜나","userId":"18133580631168845155"},"user_tz":-540},"id":"1mdVZjZ-NiBB","outputId":"985dd891-b977-43c9-94a8-67bcb3698ab9"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhyenagatha02\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.1"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/Colab Notebooks/[Microdegree] Hypotension/code/wandb/run-20231218_052725-qvftyu3j</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/hyenagatha02/KAIST%20GSDS%20Microdegree%20-%20Hypotension/runs/qvftyu3j' target=\"_blank\">cross_entropy_epoch100_batch128_expresnet1d100</a></strong> to <a href='https://wandb.ai/hyenagatha02/KAIST%20GSDS%20Microdegree%20-%20Hypotension' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/hyenagatha02/KAIST%20GSDS%20Microdegree%20-%20Hypotension' target=\"_blank\">https://wandb.ai/hyenagatha02/KAIST%20GSDS%20Microdegree%20-%20Hypotension</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/hyenagatha02/KAIST%20GSDS%20Microdegree%20-%20Hypotension/runs/qvftyu3j' target=\"_blank\">https://wandb.ai/hyenagatha02/KAIST%20GSDS%20Microdegree%20-%20Hypotension/runs/qvftyu3j</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hyenagatha02/KAIST%20GSDS%20Microdegree%20-%20Hypotension/runs/qvftyu3j?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7a3acdc7bfd0>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# -- wandb initialize with configuration\n","config={\n","    \"epochs\": args.epochs,\n","    \"batch_size\": args.batch_size,\n","    \"learning_rate\" : args.lr,\n","    \"architecture\" : args.model,\n","    \"criterion\" : args.criterion\n","}\n","wandb.init(entity='hyenagatha02', project=\"KAIST GSDS Microdegree - Hypotension\", name = str(save_dir.split('/')[-1])+str(args.model)+str(args.epochs), config=config)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3090,"status":"ok","timestamp":1702877293172,"user":{"displayName":"혜나","userId":"18133580631168845155"},"user_tz":-540},"id":"MD3AjihTNiBC","outputId":"2c6eb3f0-dff7-4125-e519-6fabcab356b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([189429, 1, 3000]) torch.Size([189429, 1])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv1d-1            [-1, 128, 3000]           2,176\n","   MyConv1dPadSame-2            [-1, 128, 3000]               0\n","       BatchNorm1d-3            [-1, 128, 3000]             256\n","              ReLU-4            [-1, 128, 3000]               0\n","            Conv1d-5            [-1, 128, 3000]           8,320\n","   MyConv1dPadSame-6            [-1, 128, 3000]               0\n","       BatchNorm1d-7            [-1, 128, 3000]             256\n","              ReLU-8            [-1, 128, 3000]               0\n","           Dropout-9            [-1, 128, 3000]               0\n","           Conv1d-10            [-1, 128, 3000]           8,320\n","  MyConv1dPadSame-11            [-1, 128, 3000]               0\n","       BasicBlock-12            [-1, 128, 3000]               0\n","      BatchNorm1d-13            [-1, 128, 3000]             256\n","             ReLU-14            [-1, 128, 3000]               0\n","          Dropout-15            [-1, 128, 3000]               0\n","           Conv1d-16            [-1, 128, 1500]           8,320\n","  MyConv1dPadSame-17            [-1, 128, 1500]               0\n","      BatchNorm1d-18            [-1, 128, 1500]             256\n","             ReLU-19            [-1, 128, 1500]               0\n","          Dropout-20            [-1, 128, 1500]               0\n","           Conv1d-21            [-1, 128, 1500]           8,320\n","  MyConv1dPadSame-22            [-1, 128, 1500]               0\n","        MaxPool1d-23            [-1, 128, 1500]               0\n","MyMaxPool1dPadSame-24            [-1, 128, 1500]               0\n","       BasicBlock-25            [-1, 128, 1500]               0\n","      BatchNorm1d-26            [-1, 128, 1500]             256\n","             ReLU-27            [-1, 128, 1500]               0\n","          Dropout-28            [-1, 128, 1500]               0\n","           Conv1d-29            [-1, 128, 1500]           8,320\n","  MyConv1dPadSame-30            [-1, 128, 1500]               0\n","      BatchNorm1d-31            [-1, 128, 1500]             256\n","             ReLU-32            [-1, 128, 1500]               0\n","          Dropout-33            [-1, 128, 1500]               0\n","           Conv1d-34            [-1, 128, 1500]           8,320\n","  MyConv1dPadSame-35            [-1, 128, 1500]               0\n","       BasicBlock-36            [-1, 128, 1500]               0\n","      BatchNorm1d-37            [-1, 128, 1500]             256\n","             ReLU-38            [-1, 128, 1500]               0\n","          Dropout-39            [-1, 128, 1500]               0\n","           Conv1d-40             [-1, 128, 750]           8,320\n","  MyConv1dPadSame-41             [-1, 128, 750]               0\n","      BatchNorm1d-42             [-1, 128, 750]             256\n","             ReLU-43             [-1, 128, 750]               0\n","          Dropout-44             [-1, 128, 750]               0\n","           Conv1d-45             [-1, 128, 750]           8,320\n","  MyConv1dPadSame-46             [-1, 128, 750]               0\n","        MaxPool1d-47             [-1, 128, 750]               0\n","MyMaxPool1dPadSame-48             [-1, 128, 750]               0\n","       BasicBlock-49             [-1, 128, 750]               0\n","      BatchNorm1d-50             [-1, 128, 750]             256\n","             ReLU-51             [-1, 128, 750]               0\n","          Dropout-52             [-1, 128, 750]               0\n","           Conv1d-53             [-1, 256, 750]          16,640\n","  MyConv1dPadSame-54             [-1, 256, 750]               0\n","      BatchNorm1d-55             [-1, 256, 750]             512\n","             ReLU-56             [-1, 256, 750]               0\n","          Dropout-57             [-1, 256, 750]               0\n","           Conv1d-58             [-1, 256, 750]          33,024\n","  MyConv1dPadSame-59             [-1, 256, 750]               0\n","       BasicBlock-60             [-1, 256, 750]               0\n","      BatchNorm1d-61             [-1, 256, 750]             512\n","             ReLU-62             [-1, 256, 750]               0\n","          Dropout-63             [-1, 256, 750]               0\n","           Conv1d-64             [-1, 256, 375]          33,024\n","  MyConv1dPadSame-65             [-1, 256, 375]               0\n","      BatchNorm1d-66             [-1, 256, 375]             512\n","             ReLU-67             [-1, 256, 375]               0\n","          Dropout-68             [-1, 256, 375]               0\n","           Conv1d-69             [-1, 256, 375]          33,024\n","  MyConv1dPadSame-70             [-1, 256, 375]               0\n","        MaxPool1d-71             [-1, 256, 375]               0\n","MyMaxPool1dPadSame-72             [-1, 256, 375]               0\n","       BasicBlock-73             [-1, 256, 375]               0\n","      BatchNorm1d-74             [-1, 256, 375]             512\n","             ReLU-75             [-1, 256, 375]               0\n","          Dropout-76             [-1, 256, 375]               0\n","           Conv1d-77             [-1, 256, 375]          33,024\n","  MyConv1dPadSame-78             [-1, 256, 375]               0\n","      BatchNorm1d-79             [-1, 256, 375]             512\n","             ReLU-80             [-1, 256, 375]               0\n","          Dropout-81             [-1, 256, 375]               0\n","           Conv1d-82             [-1, 256, 375]          33,024\n","  MyConv1dPadSame-83             [-1, 256, 375]               0\n","       BasicBlock-84             [-1, 256, 375]               0\n","      BatchNorm1d-85             [-1, 256, 375]             512\n","             ReLU-86             [-1, 256, 375]               0\n","          Dropout-87             [-1, 256, 375]               0\n","           Conv1d-88             [-1, 256, 188]          33,024\n","  MyConv1dPadSame-89             [-1, 256, 188]               0\n","      BatchNorm1d-90             [-1, 256, 188]             512\n","             ReLU-91             [-1, 256, 188]               0\n","          Dropout-92             [-1, 256, 188]               0\n","           Conv1d-93             [-1, 256, 188]          33,024\n","  MyConv1dPadSame-94             [-1, 256, 188]               0\n","        MaxPool1d-95             [-1, 256, 188]               0\n","MyMaxPool1dPadSame-96             [-1, 256, 188]               0\n","       BasicBlock-97             [-1, 256, 188]               0\n","      BatchNorm1d-98             [-1, 256, 188]             512\n","             ReLU-99             [-1, 256, 188]               0\n","         Dropout-100             [-1, 256, 188]               0\n","          Conv1d-101             [-1, 512, 188]          66,048\n"," MyConv1dPadSame-102             [-1, 512, 188]               0\n","     BatchNorm1d-103             [-1, 512, 188]           1,024\n","            ReLU-104             [-1, 512, 188]               0\n","         Dropout-105             [-1, 512, 188]               0\n","          Conv1d-106             [-1, 512, 188]         131,584\n"," MyConv1dPadSame-107             [-1, 512, 188]               0\n","      BasicBlock-108             [-1, 512, 188]               0\n","     BatchNorm1d-109             [-1, 512, 188]           1,024\n","            ReLU-110             [-1, 512, 188]               0\n","         Dropout-111             [-1, 512, 188]               0\n","          Conv1d-112              [-1, 512, 94]         131,584\n"," MyConv1dPadSame-113              [-1, 512, 94]               0\n","     BatchNorm1d-114              [-1, 512, 94]           1,024\n","            ReLU-115              [-1, 512, 94]               0\n","         Dropout-116              [-1, 512, 94]               0\n","          Conv1d-117              [-1, 512, 94]         131,584\n"," MyConv1dPadSame-118              [-1, 512, 94]               0\n","       MaxPool1d-119              [-1, 512, 94]               0\n","MyMaxPool1dPadSame-120              [-1, 512, 94]               0\n","      BasicBlock-121              [-1, 512, 94]               0\n","     BatchNorm1d-122              [-1, 512, 94]           1,024\n","            ReLU-123              [-1, 512, 94]               0\n","         Dropout-124              [-1, 512, 94]               0\n","          Conv1d-125              [-1, 512, 94]         131,584\n"," MyConv1dPadSame-126              [-1, 512, 94]               0\n","     BatchNorm1d-127              [-1, 512, 94]           1,024\n","            ReLU-128              [-1, 512, 94]               0\n","         Dropout-129              [-1, 512, 94]               0\n","          Conv1d-130              [-1, 512, 94]         131,584\n"," MyConv1dPadSame-131              [-1, 512, 94]               0\n","      BasicBlock-132              [-1, 512, 94]               0\n","     BatchNorm1d-133              [-1, 512, 94]           1,024\n","            ReLU-134              [-1, 512, 94]               0\n","         Dropout-135              [-1, 512, 94]               0\n","          Conv1d-136              [-1, 512, 47]         131,584\n"," MyConv1dPadSame-137              [-1, 512, 47]               0\n","     BatchNorm1d-138              [-1, 512, 47]           1,024\n","            ReLU-139              [-1, 512, 47]               0\n","         Dropout-140              [-1, 512, 47]               0\n","          Conv1d-141              [-1, 512, 47]         131,584\n"," MyConv1dPadSame-142              [-1, 512, 47]               0\n","       MaxPool1d-143              [-1, 512, 47]               0\n","MyMaxPool1dPadSame-144              [-1, 512, 47]               0\n","      BasicBlock-145              [-1, 512, 47]               0\n","     BatchNorm1d-146              [-1, 512, 47]           1,024\n","            ReLU-147              [-1, 512, 47]               0\n","         Dropout-148              [-1, 512, 47]               0\n","          Conv1d-149             [-1, 1024, 47]         263,168\n"," MyConv1dPadSame-150             [-1, 1024, 47]               0\n","     BatchNorm1d-151             [-1, 1024, 47]           2,048\n","            ReLU-152             [-1, 1024, 47]               0\n","         Dropout-153             [-1, 1024, 47]               0\n","          Conv1d-154             [-1, 1024, 47]         525,312\n"," MyConv1dPadSame-155             [-1, 1024, 47]               0\n","      BasicBlock-156             [-1, 1024, 47]               0\n","     BatchNorm1d-157             [-1, 1024, 47]           2,048\n","            ReLU-158             [-1, 1024, 47]               0\n","         Dropout-159             [-1, 1024, 47]               0\n","          Conv1d-160             [-1, 1024, 24]         525,312\n"," MyConv1dPadSame-161             [-1, 1024, 24]               0\n","     BatchNorm1d-162             [-1, 1024, 24]           2,048\n","            ReLU-163             [-1, 1024, 24]               0\n","         Dropout-164             [-1, 1024, 24]               0\n","          Conv1d-165             [-1, 1024, 24]         525,312\n"," MyConv1dPadSame-166             [-1, 1024, 24]               0\n","       MaxPool1d-167             [-1, 1024, 24]               0\n","MyMaxPool1dPadSame-168             [-1, 1024, 24]               0\n","      BasicBlock-169             [-1, 1024, 24]               0\n","     BatchNorm1d-170             [-1, 1024, 24]           2,048\n","            ReLU-171             [-1, 1024, 24]               0\n","         Dropout-172             [-1, 1024, 24]               0\n","          Conv1d-173             [-1, 1024, 24]         525,312\n"," MyConv1dPadSame-174             [-1, 1024, 24]               0\n","     BatchNorm1d-175             [-1, 1024, 24]           2,048\n","            ReLU-176             [-1, 1024, 24]               0\n","         Dropout-177             [-1, 1024, 24]               0\n","          Conv1d-178             [-1, 1024, 24]         525,312\n"," MyConv1dPadSame-179             [-1, 1024, 24]               0\n","      BasicBlock-180             [-1, 1024, 24]               0\n","     BatchNorm1d-181             [-1, 1024, 24]           2,048\n","            ReLU-182             [-1, 1024, 24]               0\n","         Dropout-183             [-1, 1024, 24]               0\n","          Conv1d-184             [-1, 1024, 12]         525,312\n"," MyConv1dPadSame-185             [-1, 1024, 12]               0\n","     BatchNorm1d-186             [-1, 1024, 12]           2,048\n","            ReLU-187             [-1, 1024, 12]               0\n","         Dropout-188             [-1, 1024, 12]               0\n","          Conv1d-189             [-1, 1024, 12]         525,312\n"," MyConv1dPadSame-190             [-1, 1024, 12]               0\n","       MaxPool1d-191             [-1, 1024, 12]               0\n","MyMaxPool1dPadSame-192             [-1, 1024, 12]               0\n","      BasicBlock-193             [-1, 1024, 12]               0\n","     BatchNorm1d-194             [-1, 1024, 12]           2,048\n","            ReLU-195             [-1, 1024, 12]               0\n","          Linear-196                    [-1, 2]           2,050\n","================================================================\n","Total params: 5,277,058\n","Trainable params: 5,277,058\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 156.03\n","Params size (MB): 20.13\n","Estimated Total Size (MB): 176.17\n","----------------------------------------------------------------\n"]}],"source":["# make model\n","# device_str = \"cuda\"\n","# device = torch.device(device_str if torch.cuda.is_available() else \"cpu\")\n","\n","## change the hyper-parameters for your own data\n","# (n_block, downsample_gap, increasefilter_gap) = (8, 1, 2)\n","# 34 layer (16*2+2): 16, 2, 4\n","# 98 layer (48*2+2): 48, 6, 12\n","\n","model = ResNet1D(\n","    in_channels=1, # 3000,\n","    base_filters=128, # 128, # 64 for ResNet1D, 352 for ResNeXt1D\n","    kernel_size= 16, # kernel_size,\n","    stride=2, # stride,\n","    groups=32,\n","    n_block=16, # 48, # n_block=48,\n","    n_classes=2, # 4, 3\n","    downsample_gap=2, # 6, # downsample_gap,\n","    increasefilter_gap=4, # 12, # increasefilter_gap,\n","    use_do=True)\n","model.to(device)\n","print(train_X.shape, train_Y.shape)\n","summary(model, (train_X.shape[1], train_X.shape[2])) # device=device\n","# exit()\n","\n","model.verbose = False # True\n","optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.lr)\n","# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n","# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, args.lr_decay_step, gamma=0.5)\n","# loss_func = torch.nn.CrossEntropyLoss()\n","criterion = create_criterion(args.criterion)  # default: cross_entropy\n","\n","logger = SummaryWriter(log_dir=save_dir)\n","with open(os.path.join(save_dir, 'config.json'), 'w', encoding='utf-8') as f:\n","    json.dump(vars(args), f, ensure_ascii=False, indent=4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"elapsed":791563,"status":"error","timestamp":1702878135693,"user":{"displayName":"혜나","userId":"18133580631168845155"},"user_tz":-540},"id":"y9R8-f06NiBE","outputId":"794ff611-77aa-48bd-91e0-7d6d8df6d703"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore') # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n","\n","# early_stopping\n","early_stopping = EarlyStopping(patience = 7, verbose = True)\n","\n","# train\n","best_val_loss = np.inf\n","best_val_acc = 0\n","best_val_auc = 0\n","best_val_recall = 0\n","\n","# for _ in tqdm(range(args.epochs), desc=\"epoch\", leave=False):\n","for epoch in range(args.epochs):\n","\n","    # train loop\n","    model.train()\n","\n","    loss_value = 0\n","    matches = 0\n","    train_preds_by_batch = []\n","    train_labels_by_batch = []\n","\n","    # prog_iter = tqdm(train_dataloader, desc=\"Training\", leave=False)\n","    print(\"Training...\")\n","    # for batch_idx, train_batch in enumerate(prog_iter):\n","    for batch_idx, train_batch in enumerate(train_dataloader):\n","        input_x, input_y = tuple(t.to(device) for t in train_batch)\n","        # input_x, input_y = tuple(t for t in train_batch)\n","        # input_x = input_x.to(device).float()\n","        # input_y = input_y.to(device).long()\n","\n","        optimizer.zero_grad()\n","        # preds = model(input_x)\n","        outs = model(input_x) # torch.Size([128, 2])\n","        preds = torch.argmax(outs, dim=-1) # torch.Size([128])\n","        input_y = input_y.squeeze_() # torch.Size([128, 1]) -> torch.Size([128])\n","\n","        # print('outs : ', type(outs), outs.dtype, outs.shape, outs)\n","        # print('preds : ', type(preds), preds.dtype, preds.shape, preds)\n","        # print('input_y : ', type(input_y), input_y.dtype, input_y.shape, input_y)\n","\n","        # loss = criterion(preds, input_y) # binary_cross_entropy\n","        # loss.requires_grad_(True) # binary_cross_entropy\n","        loss = criterion(outs, input_y) # cross_entropy\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        loss_value += loss.item()\n","        matches += (preds == input_y).sum().item()\n","\n","        train_preds_by_batch.extend(preds.cpu().numpy())\n","        train_labels_by_batch.extend(input_y.cpu().numpy())\n","\n","        if (batch_idx + 1) % args.log_interval == 0:\n","            train_loss = loss_value / args.log_interval\n","            train_acc = matches / args.batch_size / args.log_interval\n","\n","            train_auc = roc_auc_score(train_labels_by_batch, train_preds_by_batch)\n","            train_precision = precision_score(train_labels_by_batch, train_preds_by_batch)\n","            train_recall = recall_score(train_labels_by_batch, train_preds_by_batch)\n","            train_f1 = f1_score(train_labels_by_batch, train_preds_by_batch)\n","\n","            current_lr = get_lr(optimizer)\n","            print(\n","                f\"Epoch[{epoch+1}/{args.epochs}]({batch_idx + 1}/{len(train_dataloader)}) || \"\n","                f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || training auc {train_auc:4.4f} || \"\n","                f\"training precision {train_precision:4.4f} || training recall {train_recall:4.4f} || training f1_score {train_f1:4.4f} || lr {current_lr}\"\n","            )\n","            logger.add_scalar(\"Train/loss\", train_loss, epoch * len(train_dataloader) + batch_idx)\n","            logger.add_scalar(\"Train/accuracy\", train_acc, epoch * len(train_dataloader) + batch_idx)\n","            logger.add_scalar(\"Train/auc\", train_auc, epoch * len(train_dataloader) + batch_idx)\n","            logger.add_scalar(\"Train/precision\", train_precision, epoch * len(train_dataloader) + batch_idx)\n","            logger.add_scalar(\"Train/recall\", train_recall, epoch * len(train_dataloader) + batch_idx)\n","            logger.add_scalar(\"Train/f1_score\", train_f1, epoch * len(train_dataloader) + batch_idx)\n","\n","            loss_value = 0\n","            matches = 0\n","            train_preds_by_batch = []\n","            train_labels_by_batch = []\n","\n","    # logging wandb train phase\n","    wandb.log({\n","        'Train loss': train_loss,\n","        'Train acc': train_acc,\n","        'Train auc': train_auc,\n","        'Train precision' : train_precision,\n","        'Train recall': train_recall,\n","        'Train f1_score' : train_f1,\n","    })\n","\n","    # scheduler.step(_)\n","    # scheduler.step(train_loss)\n","\n","    # val loop\n","    with torch.no_grad():\n","\n","        model.eval()\n","        val_loss_items = []\n","        val_acc_items = []\n","\n","        # val_auc_items = []\n","        # val_precision_items = []\n","        # val_recall_items = []\n","        # val_f1_items = []\n","        # val_pass_count = 0 # for try ~ except auc\n","\n","        all_val_preds = []\n","        all_val_labels = []\n","\n","        # prog_iter_test = tqdm(val_dataloader, desc=\"Testing\", leave=False)\n","        print()\n","        print(\"Calculating validation results...\")\n","        # for batch_idx, val_batch in enumerate(prog_iter_test):\n","        for val_batch in val_dataloader:\n","            input_x, input_y = tuple(t.to(device) for t in val_batch)\n","            # input_x, input_y = tuple(t for t in val_batch)\n","            # input_x = input_x.to(device).float()\n","            # input_y = input_y.to(device).long()\n","\n","            # preds = model(input_x)\n","            outs = model(input_x)\n","            preds = torch.argmax(outs, dim=-1)\n","            input_y = input_y.squeeze_()\n","\n","            # print('outs : ', type(outs), outs.dtype, outs.shape, outs)\n","            # print('preds : ', type(preds), preds.dtype, preds.shape, preds)\n","            # print('input_y : ', type(input_y), input_y.dtype, input_y.shape, input_y)\n","\n","            # loss_item = criterion(preds, input_y).item() # binary_cross_entropy\n","            loss_item = criterion(outs, input_y).item() # cross_entrypy\n","            acc_item = (input_y == preds).sum().item()\n","\n","            all_val_preds.extend(preds.cpu().numpy())\n","            all_val_labels.extend(input_y.cpu().numpy())\n","\n","            # auc_item = roc_auc_score(input_y.cpu().numpy(), preds.cpu().numpy()).item()\n","            # try:\n","            #     auc_item = roc_auc_score(input_y.cpu().numpy(), preds.cpu().numpy()).item()\n","            # except ValueError:\n","            #     auc_item = 0 # pass\n","            #     val_pass_count += 1\n","            # precision_item = precision_score(input_y.cpu().numpy(), preds.cpu().numpy()).item()\n","            # recall_item = recall_score(input_y.cpu().numpy(), preds.cpu().numpy()).item()\n","            # f1_item = f1_score(input_y.cpu().numpy(), preds.cpu().numpy()).item()\n","\n","            val_loss_items.append(loss_item)\n","            val_acc_items.append(acc_item)\n","\n","            # val_auc_items.append(auc_item)\n","            # val_precision_items.append(precision_item)\n","            # val_recall_items.append(recall_item)\n","            # val_f1_items.append(f1_item)\n","\n","    val_loss = np.sum(val_loss_items) / len(val_dataloader)\n","    val_acc = np.sum(val_acc_items) / len(val_dataset)\n","    best_val_loss = min(best_val_loss, val_loss)\n","\n","    # val_auc = np.sum(val_auc_items) / len(val_dataloader)\n","    # val_precision = np.sum(val_precision_items) / len(val_dataloader)\n","    # val_recall = np.sum(val_recall_items) / len(val_dataloader)\n","    # val_f1 = np.sum(val_f1_items) / len(val_dataloader)\n","    # best_val_acc = max(best_val_acc, val_acc)\n","    # best_val_auc = max(best_val_auc, val_auc)\n","\n","    val_auc = roc_auc_score(all_val_labels, all_val_preds)\n","    val_precision = precision_score(all_val_labels, all_val_preds)\n","    val_recall = recall_score (all_val_labels, all_val_preds)\n","    val_f1 = f1_score (all_val_labels, all_val_preds)\n","    best_val_acc = max(best_val_acc, val_acc)\n","    best_val_auc = max(best_val_auc, val_auc)\n","    best_val_recall = max(best_val_recall, val_recall)\n","\n","    # early stopping\n","    early_stopping(val_loss, model) # 현재 과적합 상황 추적\n","    if early_stopping.early_stop: # 조건 만족 시 조기 종료\n","        break\n","    \n","    if val_auc > best_val_acc:\n","        print(f\"New best model for val AUC : {val_auc:4.4f}! saving the best model..\")\n","        torch.save(model.state_dict(), f\"{save_dir}/best.pth\")\n","        best_val_auc = val_auc\n","    torch.save(model.state_dict(), f\"{save_dir}/last.pth\")\n","    print(\n","        f\"[Val] acc : {val_acc:4.2%}, loss : {val_loss:4.4}, auc : {val_auc:4.4f}, recall : {val_recall:4.4f}, precision : {val_precision:4.4f}, f1_score : {val_f1:4.4f} || \"\n","        f\"Best acc : {best_val_acc:4.2%}, Best loss : {best_val_loss:4.4}, best AUC : {best_val_auc:4.4f}, best Recall : {best_val_recall:4.4f}\"\n","    )\n","    logger.add_scalar(\"Val/loss\", val_loss, epoch)\n","    logger.add_scalar(\"Val/accuracy\", val_acc, epoch)\n","    logger.add_scalar(\"Val/auc\", val_auc, epoch)\n","    logger.add_scalar(\"Val/precision\", val_precision, epoch)\n","    logger.add_scalar(\"Val/recall\", val_recall, epoch)\n","    logger.add_scalar(\"Val/f1_score\", val_f1, epoch)\n","    print()\n","\n","    # logging wandb valid phase\n","    wandb.log({\n","        'Valid loss': val_loss,\n","        'Valid acc': val_acc,\n","        'Valid auc': val_auc,\n","        'Valid precision' : val_precision,\n","        'Valid recall': val_recall,\n","        'Valid f1_score' : val_f1,\n","    })\n","\n","wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bRwD07aANiBE"},"outputs":[],"source":["# test loop\n","with torch.no_grad():\n","    \n","    model.eval()\n","\n","    test_loss_items = []\n","    test_acc_items = []\n","    all_test_preds = []\n","    all_test_labels = []\n","    \n","    # prog_iter_test = tqdm(test_dataloader, desc=\"Testing\", leave=False)\n","    print(\"Testing results...\")\n","    # for batch_idx, test_batch in enumerate(prog_iter_test):\n","    for test_batch in test_dataloader:\n","        input_x, input_y = tuple(t.to(device) for t in test_batch)\n","\n","        outs = model(input_x)\n","        preds = torch.argmax(outs, dim=-1)\n","        input_y = input_y.squeeze_()\n","        \n","        # loss_item = criterion(preds, input_y).item() # binary_cross_entropy\n","        loss_item = criterion(outs, input_y).item() # cross_entrypy\n","        acc_item = (input_y == preds).sum().item()\n","\n","        test_loss_items.append(loss_item)\n","        test_acc_items.append(acc_item)\n","\n","        all_test_preds.extend(preds.cpu().numpy())\n","        all_test_labels.extend(input_y.cpu().numpy())\n","\n","test_loss = np.sum(test_loss_items) / len(test_dataloader)\n","test_acc = np.sum(test_acc_items) / len(test_dataset)\n","test_auc = roc_auc_score(all_test_labels, all_test_preds)\n","test_precision = precision_score(all_test_labels, all_test_preds)\n","test_recall = recall_score (all_test_labels, all_test_preds)\n","test_f1 = f1_score (all_test_labels, all_test_preds)\n","\n","# test_loss_items = []\n","# test_acc_items = []\n","\n","# for pred, label in zip(preds, test_Y.cpu().numpy()):\n","#     loss_item = criterion(pred, label).item()\n","#     acc_item = (pred == label).sum().item()\n","\n","#     test_loss_items.append(loss_item)\n","#     test_acc_items.append(acc_item)\n","\n","# test_loss = np.sum(test_loss_items) / len(test_dataloader)\n","# test_acc = np.sum(test_acc_items) / len(test_dataset)\n","\n","# test_auc = roc_auc_score(all_test_labels, all_test_preds)\n","# test_precision = precision_score(all_test_labels, all_test_preds)\n","# test_recall = recall_score (all_test_labels, all_test_preds)\n","# test_f1 = f1_score (all_test_labels, all_test_preds)\n","\n","print(\n","    f\"[test] acc : {test_acc:4.2%}, loss: {test_loss:4.4}, auc : {test_auc:4.4f}, recall : {test_recall:4.4f}, precision : {test_precision:4.4f}, f1_score : {test_f1:4.4f} ||\"\n",")\n","\n","output_dir = os.environ.get('SM_OUTPUT_DATA_DIR', './output')\n","save_path = os.path.join(output_dir, f'./preds.pkl')\n","pickle.dump((all_test_preds, all_test_labels), open(save_path, 'wb'))\n","print(f\"Inference Done! Inference result saved at {save_path}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
